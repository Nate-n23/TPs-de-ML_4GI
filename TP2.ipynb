{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1efc538",
   "metadata": {},
   "source": [
    "# TP2  DE MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc5fb16",
   "metadata": {},
   "source": [
    "## PHASE 1 : REGRESSION LINEAIRE AVANCEE ET COMPROMIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d32e6bb",
   "metadata": {},
   "source": [
    "### 1.1 Préparation des données et OLS\n",
    "Nous utilisons lee dataset Diabetes pour prédire la progression de la maladie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc88a8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS: RMSE=53.85, R2=0.45\n",
      "Coefficients OLS: [  1.75 -11.51  25.61  16.83 -44.45  24.64   7.68  13.14  35.16   2.35]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Tâche 1.1 & 1.2 : Chargement et OLS\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalisation\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Entraînement OLS (Ordinary Least Squares)\n",
    "ols_reg = LinearRegression()\n",
    "ols_reg.fit(X_train_scaled, y_train)\n",
    "y_pred_ols = ols_reg.predict(X_test_scaled)\n",
    "\n",
    "# Évaluation\n",
    "rmse_ols = np.sqrt(mean_squared_error(y_test, y_pred_ols))\n",
    "r2_ols = r2_score(y_test, y_pred_ols)\n",
    "\n",
    "print(f\"OLS: RMSE={rmse_ols:.2f}, R2={r2_ols:.2f}\")\n",
    "print(\"Coefficients OLS:\", np.round(ols_reg.coef_, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c2b6c8",
   "metadata": {},
   "source": [
    "### 1.2 Théorie : Biais, Variance et Régularisation\n",
    "\n",
    "Tâche 1.3\n",
    "\n",
    "Le Biais : Erreur due à des hypothèses trop simplistes (ex: utiliser un modèle linéaire pour des données complexes). Cela mène au sous-apprentissage (underfitting).\n",
    "\n",
    "La Variance : Erreur due à une trop grande sensibilité du modèle aux fluctuations du dataset d'entraînement. Cela mène au sur-apprentissage (overfitting).\n",
    "\n",
    "La Régularisation : En ajoutant une pénalité aux coefficients trop élevés, on accepte un peu plus de biais pour réduire drastiquement la variance, ce qui améliore la généralisation sur de nouvelles données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e805e8d",
   "metadata": {},
   "source": [
    "Tâche 1.4 : Ridge Regression ($L_2$) 3\n",
    "La pénalité $L_2$ ajoute la somme des carrés des coefficients à la fonction de perte.Pourquoi elle ne s'annule jamais ? Mathématiquement, la pénalité est une parabole. La dérivée diminue à mesure que le coefficient s'approche de zéro, mais ne \"pousse\" pas brutalement le coefficient à zéro. Les poids deviennent très petits mais restent non-nuls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6108b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge (alpha=1.0): RMSE CV=55.92\n",
      "Coefficients Ridge: [  1.80734179 -11.44818951  25.73269892  16.73429974 -34.67195409\n",
      "  17.05307485   3.36991411  11.76426044  31.3783838    2.45813922]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Entrainement avec une valeur alpha initiale\n",
    "alpha_initial = 1.0\n",
    "ridge_reg = Ridge(alpha=alpha_initial)\n",
    "ridge_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluation by Cross-Validation (5-folds)\n",
    "scores_ridge = cross_val_score(ridge_reg, X_train_scaled, y_train, scoring='neg_root_mean_squared_error', cv=5)\n",
    "rmse_cv_ridge = -scores_ridge.mean()\n",
    "\n",
    "print(f\"\\nRidge (alpha={alpha_initial}): RMSE CV={rmse_cv_ridge:.2f}\")\n",
    "print(\"Coefficients Ridge:\", ridge_reg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87a9ea1",
   "metadata": {},
   "source": [
    "### 1.3 Sparité et optimisation (LASSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ae8f803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO (alpha=0.1): RMSE=53.71, R2=0.46\n",
      "Coefficients LASSO : [  1.73045056 -11.31635911  25.82462699  16.64425156 -29.35841191\n",
      "  13.27584411   0.5479479   10.23616805  29.63282611   2.39347521]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Tâche 1.5 : Implémentation d'un modèle LASSO avec un alpha initial\n",
    "alpha_lasso_init = 0.1\n",
    "lasso_reg = Lasso(alpha=alpha_lasso_init, max_iter=10000)\n",
    "\n",
    "# Entraînement sur les données normalisées\n",
    "lasso_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prédiction\n",
    "y_pred_lasso = lasso_reg.predict(X_test_scaled)\n",
    "\n",
    "# Évaluation\n",
    "rmse_lasso = np.sqrt(mean_squared_error(y_test, y_pred_lasso))\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "print(f\"LASSO (alpha={alpha_lasso_init}): RMSE={rmse_lasso:.2f}, R2={r2_lasso:.2f}\")\n",
    "print(\"Coefficients LASSO :\", lasso_reg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb16730c",
   "metadata": {},
   "source": [
    "Sparsité : Un modèle est dit \"creux\" (sparse) lorsqu'un grand nombre de ses coefficients sont exactement égaux à zéro.Pourquoi le $L_1$ annule les coefficients ? La forme géométrique de la pénalité $L_1$ (un diamant) possède des coins sur les axes. Lors de l'optimisation, la solution a de fortes chances de toucher un de ces coins, annulant ainsi la variable. C'est une sélection de caractéristiques intrinsèque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "430678e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha optimal Ridge : 55.9081\n",
      "Alpha optimal LASSO : 0.1417\n",
      "Variables annulées par LASSO : 1 sur 10\n"
     ]
    }
   ],
   "source": [
    "# Tâche 1.6 : Recherche des Hyperparamètres Optimaux\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "\n",
    "# Tests sur 100 valeurs de alpha\n",
    "alphas = np.logspace(-3, 2, 100)\n",
    "\n",
    "ridge_cv = RidgeCV(alphas=alphas, cv=10)\n",
    "ridge_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "lasso_cv = LassoCV(alphas=np.logspace(-3, 0, 100), cv=10, max_iter=10000)\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Alpha optimal Ridge : {ridge_cv.alpha_:.4f}\")\n",
    "print(f\"Alpha optimal LASSO : {lasso_cv.alpha_:.4f}\")\n",
    "\n",
    "#Final LASSO Model\n",
    "lasso_final = LassoCV(alphas=[lasso_cv.alpha_], cv=10, max_iter=10000)\n",
    "lasso_final.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Analyse de la sparsité du LASSO\n",
    "print(f\"Variables annulées par LASSO : {np.sum(lasso_cv.coef_ == 0)} sur {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a1b923",
   "metadata": {},
   "source": [
    "## PHASE 2 : MLOps ET MISE EN PRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b573541",
   "metadata": {},
   "source": [
    "### 2.1 Packaging et Dépendances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab2f1f1",
   "metadata": {},
   "source": [
    "Tâche 2.1 : Pourquoi sauvegarder le scaler ?  Il est impératif de sauvegarder l'objet StandardScaler car les nouvelles données en production doivent subir exactement la même transformation (même moyenne et même écart-type) que les données d'entraînement. Utiliser un nouveau scaler sur les données de production fausserait totalement les prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b36f3206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler and LASSO model saved for deployment.\n",
      "Prediction for the test example: 140.05\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Tâche 2.1 : Sauvegarde du modèle et du scaler\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(lasso_final, 'lasso_model.pkl')\n",
    "print(\"Scaler and LASSO model saved for deployment.\")\n",
    "\n",
    "# Fonction de prédiction corrigée\n",
    "def predict_new_data(raw_data, model_path='lasso_model.pkl', scaler_path='scaler.pkl'):\n",
    "    \"\"\"Simule le pipeline de prédiction en production.\"\"\"\n",
    "    try:\n",
    "        # Chargement des objets\n",
    "        loaded_scaler = joblib.load(scaler_path)\n",
    "        loaded_model = joblib.load(model_path)\n",
    "\n",
    "        # Etape 1: Transformation des données brutes \n",
    "        # On s'assure que raw_data est au bon format (2D array pour sklearn)\n",
    "        data_to_predict = np.array(raw_data).reshape(1, -1)\n",
    "        scaled_data = loaded_scaler.transform(data_to_predict)\n",
    "\n",
    "        # Etape 2: Prédiction \n",
    "        prediction = loaded_model.predict(scaled_data)[0]\n",
    "        return prediction\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: Model or scaler files not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test de la fonction avec un point du jeu de test [cite: 230]\n",
    "# Utilisation de .iloc[0] si X_test est un DataFrame Pandas\n",
    "example_raw_input = X_test[0] if isinstance(X_test, np.ndarray) else X_test.iloc[0]\n",
    "predicted_value = predict_new_data(example_raw_input)\n",
    "\n",
    "if predicted_value is not None:\n",
    "    print(f\"Prediction for the test example: {predicted_value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7371f",
   "metadata": {},
   "source": [
    "### 2.2 Tracking avec MLflow\n",
    "\n",
    "MLflow permet de garder un historique de toutes les expériences pour comparer les modèles objectivement ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53f7969f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in ./.venv/lib/python3.12/site-packages (3.8.1)\n",
      "Requirement already satisfied: mlflow-skinny==3.8.1 in ./.venv/lib/python3.12/site-packages (from mlflow) (3.8.1)\n",
      "Requirement already satisfied: mlflow-tracing==3.8.1 in ./.venv/lib/python3.12/site-packages (from mlflow) (3.8.1)\n",
      "Requirement already satisfied: Flask-CORS<7 in ./.venv/lib/python3.12/site-packages (from mlflow) (6.0.2)\n",
      "Requirement already satisfied: Flask<4 in ./.venv/lib/python3.12/site-packages (from mlflow) (3.1.2)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in ./.venv/lib/python3.12/site-packages (from mlflow) (1.18.1)\n",
      "Requirement already satisfied: cryptography<47,>=43.0.0 in ./.venv/lib/python3.12/site-packages (from mlflow) (46.0.3)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in ./.venv/lib/python3.12/site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in ./.venv/lib/python3.12/site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: gunicorn<24 in ./.venv/lib/python3.12/site-packages (from mlflow) (23.0.0)\n",
      "Requirement already satisfied: huey<3,>=2.5.0 in ./.venv/lib/python3.12/site-packages (from mlflow) (2.6.0)\n",
      "Requirement already satisfied: matplotlib<4 in ./.venv/lib/python3.12/site-packages (from mlflow) (3.10.8)\n",
      "Requirement already satisfied: numpy<3 in ./.venv/lib/python3.12/site-packages (from mlflow) (2.4.1)\n",
      "Requirement already satisfied: pandas<3 in ./.venv/lib/python3.12/site-packages (from mlflow) (2.3.3)\n",
      "Requirement already satisfied: pyarrow<23,>=4.0.0 in ./.venv/lib/python3.12/site-packages (from mlflow) (22.0.0)\n",
      "Requirement already satisfied: scikit-learn<2 in ./.venv/lib/python3.12/site-packages (from mlflow) (1.8.0)\n",
      "Requirement already satisfied: scipy<2 in ./.venv/lib/python3.12/site-packages (from mlflow) (1.17.0)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in ./.venv/lib/python3.12/site-packages (from mlflow) (2.0.45)\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (6.2.4)\n",
      "Requirement already satisfied: click<9,>=7.0 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (8.3.1)\n",
      "Requirement already satisfied: cloudpickle<4 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (3.1.2)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (0.78.0)\n",
      "Requirement already satisfied: fastapi<1 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (0.128.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (3.1.46)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (8.7.1)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (1.39.1)\n",
      "Requirement already satisfied: packaging<26 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (25.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (6.33.4)\n",
      "Requirement already satisfied: pydantic<3,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (2.12.5)\n",
      "Requirement already satisfied: python-dotenv<2,>=0.19.0 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (1.2.1)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (6.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (2.32.5)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (0.5.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (4.15.0)\n",
      "Requirement already satisfied: uvicorn<1 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow) (0.40.0)\n",
      "Requirement already satisfied: Mako in ./.venv/lib/python3.12/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
      "Requirement already satisfied: cffi>=2.0.0 in ./.venv/lib/python3.12/site-packages (from cryptography<47,>=43.0.0->mlflow) (2.0.0)\n",
      "Requirement already satisfied: google-auth~=2.0 in ./.venv/lib/python3.12/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow) (2.47.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in ./.venv/lib/python3.12/site-packages (from docker<8,>=4.0.0->mlflow) (2.6.3)\n",
      "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in ./.venv/lib/python3.12/site-packages (from fastapi<1->mlflow-skinny==3.8.1->mlflow) (0.50.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in ./.venv/lib/python3.12/site-packages (from fastapi<1->mlflow-skinny==3.8.1->mlflow) (0.0.4)\n",
      "Requirement already satisfied: blinker>=1.9.0 in ./.venv/lib/python3.12/site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in ./.venv/lib/python3.12/site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in ./.venv/lib/python3.12/site-packages (from Flask<4->mlflow) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in ./.venv/lib/python3.12/site-packages (from Flask<4->mlflow) (3.0.3)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in ./.venv/lib/python3.12/site-packages (from Flask<4->mlflow) (3.1.5)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./.venv/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.8.1->mlflow) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./.venv/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.8.1->mlflow) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow) (4.9.1)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in ./.venv/lib/python3.12/site-packages (from graphene<4->mlflow) (3.2.7)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in ./.venv/lib/python3.12/site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in ./.venv/lib/python3.12/site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.12/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.8.1->mlflow) (3.23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib<4->mlflow) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib<4->mlflow) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.12/site-packages (from matplotlib<4->mlflow) (3.3.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in ./.venv/lib/python3.12/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.8.1->mlflow) (0.60b1)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas<3->mlflow) (2025.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.8.1->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.8.1->mlflow) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.8.1->mlflow) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.8.1->mlflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.8.1->mlflow) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.8.1->mlflow) (2026.1.4)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./.venv/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow) (0.6.2)\n",
      "Requirement already satisfied: joblib>=1.3.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn<2->mlflow) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
      "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.12/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in ./.venv/lib/python3.12/site-packages (from starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.8.1->mlflow) (4.12.1)\n",
      "Requirement already satisfied: h11>=0.8 in ./.venv/lib/python3.12/site-packages (from uvicorn<1->mlflow-skinny==3.8.1->mlflow) (0.16.0)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography<47,>=43.0.0->mlflow) (2.23)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bd619c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/18 19:27:35 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.schemas\n",
      "2026/01/18 19:27:35 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.tables\n",
      "2026/01/18 19:27:35 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.types\n",
      "2026/01/18 19:27:35 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.constraints\n",
      "2026/01/18 19:27:35 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.defaults\n",
      "2026/01/18 19:27:35 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.comments\n",
      "2026/01/18 19:27:35 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2026/01/18 19:27:35 INFO mlflow.store.db.utils: Updating database tables\n",
      "2026/01/18 19:27:35 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/01/18 19:27:35 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2026/01/18 19:27:35 INFO alembic.runtime.migration: Running upgrade  -> 451aebb31d03, add metric step\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade 0584bdc529eb -> 400f98739977, add logged model tables\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade 400f98739977 -> 6953534de441, add step to inputs table\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade 6953534de441 -> bda7b8c39065, increase_model_version_tag_value_limit\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade bda7b8c39065 -> cbc13b556ace, add V3 trace schema columns\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade cbc13b556ace -> 770bee3ae1dd, add assessments table\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade 770bee3ae1dd -> a1b2c3d4e5f6, add spans table\n",
      "2026/01/18 19:27:36 INFO alembic.runtime.migration: Running upgrade a1b2c3d4e5f6 -> de4033877273, create entity_associations table\n",
      "2026/01/18 19:27:37 INFO alembic.runtime.migration: Running upgrade de4033877273 -> 1a0cddfcaa16, Add webhooks and webhook_events tables\n",
      "2026/01/18 19:27:37 INFO alembic.runtime.migration: Running upgrade 1a0cddfcaa16 -> 534353b11cbc, add scorer tables\n",
      "2026/01/18 19:27:37 INFO alembic.runtime.migration: Running upgrade 534353b11cbc -> 71994744cf8e, add evaluation datasets\n",
      "2026/01/18 19:27:37 INFO alembic.runtime.migration: Running upgrade 71994744cf8e -> 3da73c924c2f, add outputs to dataset record\n",
      "2026/01/18 19:27:37 INFO alembic.runtime.migration: Running upgrade 3da73c924c2f -> bf29a5ff90ea, add jobs table\n",
      "2026/01/18 19:27:37 INFO alembic.runtime.migration: Running upgrade bf29a5ff90ea -> 1bd49d398cd23, add secrets tables\n",
      "2026/01/18 19:27:37 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/01/18 19:27:37 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2026/01/18 19:27:37 INFO mlflow.tracking.fluent: Experiment with name 'TP_Advanced_Regression' does not exist. Creating a new experiment.\n",
      "2026/01/18 19:27:37 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Run 'LASSO_Optimal' enregistré avec succès.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Configuration de l'expérience\n",
    "mlflow.set_experiment(\"TP_Advanced_Regression\")\n",
    "\n",
    "def log_model_results(model_name, params, metrics, model):\n",
    "    \n",
    "    # Enregistre les résultats d'un modèle dans MLflow de façon modulaire.\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Hyperparameter \n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Metric Logging \n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # Model Logging \n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        print(f\"MLflow Run '{model_name}' enregistré avec succès.\")\n",
    "\n",
    "# Exemple d'application pour le modèle LASSO\n",
    "\n",
    "# 1. Préparation des paramètres\n",
    "lasso_params = {\n",
    "    \"alpha\": lasso_cv.alpha_, \n",
    "    \"solver\": \"cd\", \n",
    "    \"penalty\": \"l1\",\n",
    "    \"selection\": \"cyclic\"\n",
    "}\n",
    "\n",
    "# 2. Calcul des métriques sur le test set\n",
    "y_pred_lasso = lasso_cv.predict(X_test_scaled)\n",
    "rmse_lasso = np.sqrt(mean_squared_error(y_test, y_pred_lasso))\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "lasso_metrics = {\n",
    "    \"test_rmse\": rmse_lasso, \n",
    "    \"test_r2\": r2_lasso\n",
    "}\n",
    "\n",
    "# 3. Appel de la fonction (Structure conforme au Code 2)\n",
    "log_model_results(\"LASSO_Optimal\", lasso_params, lasso_metrics, lasso_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07245878",
   "metadata": {},
   "source": [
    "### 2.3 Conteneurisation (Docker)\n",
    "\n",
    "Tâche 2.4 : Rôle des commandes Docker:\n",
    "\n",
    "Le Dockerfile est un script contenant une série d'instructions permettant de construire automatiquement une image isolée contenant votre modèle et son environnement d'exécution.\n",
    "\n",
    "FROM : Définit l'image de base (le système d'exploitation et l'environnement minimal, ex: Python).\n",
    "\n",
    "COPY : Transfère les fichiers locaux (code, modèles .pkl) dans l'image Docker.\n",
    "\n",
    "CMD : Définit la commande par défaut qui s'exécute au démarrage du conteneur (ex: lancer le serveur API)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c966a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "# 1. Image de base légère avec Python\n",
    "FROM python:3.9-slim\n",
    "\n",
    "# 2. Définition du répertoire de travail dans le conteneur\n",
    "WORKDIR /app\n",
    "\n",
    "# 3. Copie du fichier des dépendances et installation\n",
    "# requirements.txt doit contenir : scikit-learn, numpy, joblib, flask\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# 4. Copie des fichiers locaux vers le conteneur\n",
    "COPY lasso_model.pkl .\n",
    "COPY scaler.pkl .\n",
    "COPY app.py .\n",
    "\n",
    "# 5. Commande de lancement de l'application\n",
    "CMD [\"python\", \"app.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2440f06",
   "metadata": {},
   "source": [
    "## Conclusion et Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c946e2",
   "metadata": {},
   "source": [
    "Tâche 3.1 : Git, MLflow et Docker  Ce trio forme la base du CI/CD en ML :\n",
    "\n",
    "L'intégration de ces trois outils est fondamentale pour créer des chaînes de CI/CD (Intégration et Déploiement Continus) robustes:\n",
    "\n",
    "Git : Assure le versionnage du code source. Il permet la collaboration et garantit que chaque modification du pipeline peut être tracée et annulée si nécessaire.\n",
    "\n",
    "MLflow : Gère le cycle de vie du modèle. Il permet de comparer les expériences (tracking) et de versionner les modèles eux-mêmes (Model Registry), assurant ainsi que l'on déploie toujours la version la plus performante.\n",
    "\n",
    "Docker : Garantit la reproductibilité technique. Il élimine le problème du \"ça marche sur ma machine\" en emballant le modèle et ses dépendances dans un environnement immuable\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9361dc3b",
   "metadata": {},
   "source": [
    "Tâche 3.2 : Monitoring en production  Outre le RMSE, il faut surveiller :\n",
    "\n",
    "Une fois le modèle en production, le RMSE ne suffit plus. Deux aspects cruciaux doivent être surveillés:\n",
    "\n",
    "\n",
    "Data Drift (Dérive des données) : Il s'agit de surveiller si les propriétés statistiques des données d'entrée changent au fil du temps par rapport aux données d'entraînement (ex: changement de comportement des utilisateurs).\n",
    "\n",
    "Concept Drift (Dérive du concept) : C'est le cas où la relation entre les variables d'entrée et la cible change (ex: une crise économique qui change brutalement la valeur des indicateurs de santé sans que les données des patients ne changent)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# üß† Travaux Pratiques de Machine Learning - 4GI

Bienvenue dans ce d√©p√¥t regroupant l'ensemble des travaux pratiques de Machine Learning. Ce projet a pour but de vous guider √† travers les diff√©rentes √©tapes du cycle de vie d'un projet ML, de la pr√©paration des donn√©es jusqu'au d√©ploiement de mod√®les complexes.

---

## üöÄ Installation Rapide

**Pr√©requis :** Avoir [Python 3.9+](https://www.python.org/downloads/) install√©.

1.  **R√©cup√©rer le projet :**
    ```bash
    git clone https://github.com/Nate-n23/TPs-de-ML_4GI.git
    cd TPs-de-ML_4GI
    ```

2.  **Installer les outils n√©cessaires :**
    ```bash
    pip install -r requirements.txt
    ```

3.  **Lancer les notebooks :**
    ```bash
    jupyter notebook
    ```

---

## üìÇ Contenu des TPs

Voici une vue d'ensemble pour comprendre rapidement ce que contient chaque session :

### [TP1 : Introduction aux Pipelines ML](TP1.ipynb)
**Objectif :** Pr√©dire le prix de logements en Californie.
*   **Ce qu'on y fait :** Nettoyage des donn√©es, visualisation g√©ographique, et cr√©ation d'un premier mod√®le (Random Forest).
*   **Notions cl√©s :** Pr√©paration de donn√©es, Feature Engineering, Score $R^2$.

### [TP2 : R√©gression Avanc√©e & MLOps](TP2.ipynb)
**Objectif :** Ma√Ætriser la r√©gression et la mise en production.
*   **Ce qu'on y fait :** Comparaison de mod√®les (Ridge vs Lasso), suivi des exp√©riences avec MLflow et conteneurisation avec Docker.
*   **Notions cl√©s :** Sur-apprentissage (Overfitting), R√©gularisation, MLOps.

### [TP3 : Apprentissage Non-Supervis√©](TP3.ipynb)
**Objectif :** D√©couvrir des structures cach√©es dans les donn√©es (Clustering).
*   **Ce qu'on y fait :** Segmentation client avec K-Means et GMM, et r√©duction de dimension pour visualiser les donn√©es (PCA, t-SNE).
*   **Notions cl√©s :** Clustering, Silhouette Score, Visualisation 2D/3D.

### [TP4 : Classification M√©dicale & Incertitude (EDL)](TP4.ipynb)
**Objectif :** Diagnostiquer des pathologies et quantifier l'incertitude des pr√©dictions.
*   **Ce qu'on y fait :** Comparaison de mod√®les probabilistes (Naive Bayes, KNN) sur donn√©es synth√©tiques et simulation/√©tude th√©orique du *Evidential Deep Learning* (EDL).
*   **Notions cl√©s :** Classification, K-NN, Incertitude (Al√©atoire/Epist√©mique), Th√©orie de Dempster-Shafer.

---

## üõ† Structure du Projet

*   `TP1.ipynb` √† `TP4.ipynb` : Les cours interactifs et exercices.
*   `requirements.txt` : Liste des librairies √† installer.
*   `mlruns/` : Dossier de suivi des exp√©riences (MLflow).
*   `*.pkl / *.onnx` : Mod√®les entra√Æn√©s sauvegard√©s.
